{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import torch\n",
    "import mcubes\n",
    "import numpy as np\n",
    "from skgstat import Variogram\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_598397/3167719386.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nerf_model = torch.load(pth_file).to(device)\n"
     ]
    }
   ],
   "source": [
    "# Model: Suzanne (Monkey head). 100 images normal, 100 images with right ear removed.\n",
    "device = 'cuda'\n",
    "pth_file = 'experiments/suzanne/set100/models/M0.pth'\n",
    "nerf_model = torch.load(pth_file).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eherrin@ad.ufl.edu/anaconda3/envs/nerf3Dchange/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Grid of points on scne p_XYZ\n",
    "N = 35\n",
    "scale = 1.5\n",
    "x = torch.linspace(-scale, scale, N, device=device)\n",
    "y = torch.linspace(-scale, scale, N, device=device)\n",
    "z = torch.linspace(-scale, scale, N, device=device)\n",
    "x, y, z = torch.meshgrid((x, y, z))\n",
    "xyz = torch.cat((x.reshape(-1, 1), y.reshape(-1, 1), z.reshape(-1, 1)), dim=1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical perspective view directions\n",
    "view_directions = torch.tensor([\n",
    "    [0, 0, 1],  # Top-down\n",
    "    [math.cos(math.radians(45)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(45)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(30))],  # Front-right (30° elevation, 45° azimuth)\n",
    "    [math.cos(math.radians(-45)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(-45)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(30))],  # Front-left (30° elevation, -45° azimuth)\n",
    "    [math.cos(math.radians(135)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(135)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(30))],  # Back-right (30° elevation, 135° azimuth)\n",
    "    [math.cos(math.radians(-135)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(-135)) * math.cos(math.radians(30)), \n",
    "     math.sin(math.radians(30))]   # Back-left (30° elevation, -135° azimuth)\n",
    "], device=device)\n",
    "\n",
    "# Compute averaged RGB from 5 views\n",
    "averaged_rgb = torch.zeros(xyz.shape[0], 3, device=device)\n",
    "for direction in view_directions:\n",
    "    rgb, _ = nerf_model.forward(xyz, direction.expand(xyz.shape[0], -1))\n",
    "    averaged_rgb += rgb\n",
    "\n",
    "averaged_rgb /= len(view_directions)\n",
    "\n",
    "xyz = xyz.cpu().detach().numpy()\n",
    "averaged_rgb = averaged_rgb.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking: How we filter the points we will consider\n",
    "Helps with restricting points we are interested in estimating change for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = np.quantile(averaged_rgb.mean(axis=1), 0.5)\n",
    "mask = averaged_rgb.mean(axis=1) >= threshold_value\n",
    "\n",
    "# Filter points and RGB values\n",
    "filtered_xyz = xyz[mask]\n",
    "filtered_rgb = averaged_rgb[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the Variogram: color\n",
    "Core idea: correlation between samples decreases over distance.\n",
    "A measure of spatial continuity. Finds the semi-variance for all points in our space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_variogram = Variogram(\n",
    "    filtered_xyz,\n",
    "    filtered_rgb.mean(axis=1),\n",
    "    model='spherical', # The spherical model increases linearly at short distances and levels off at a certain range, indicating that beyond this range, data points are uncorrelated.\n",
    "    normalize=False,\n",
    "    nugget=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining point-wise uncertanties from the Variogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_distances = squareform(pdist(filtered_xyz)) # distance between every point for each point\n",
    "bin_edges = color_variogram.bins\n",
    "bin_uncertainties = color_variogram.experimental # gets the semi-variance (dismilarity measure) for points in each distance based bin of the variogram\n",
    "point_uncertainties = np.zeros(filtered_xyz.shape[0])\n",
    "\n",
    "# determine uncertainty for each point based on the average semi-variance of neighboring points\n",
    "for i in range(filtered_xyz.shape[0]):\n",
    "    distances = pairwise_distances[i]\n",
    "    bin_indices = np.digitize(distances, bin_edges, right=True)\n",
    "    neighbor_uncertainties = bin_uncertainties[bin_indices - 1]\n",
    "    point_uncertainties[i] = np.mean(neighbor_uncertainties)\n",
    "\n",
    "# Normalizing uncertainties [0,1]\n",
    "point_uncertainties = (point_uncertainties - np.min(point_uncertainties)) / (\n",
    "    np.max(point_uncertainties) - np.min(point_uncertainties)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_598397/1007119914.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colormap = cm.get_cmap('inferno')\n"
     ]
    }
   ],
   "source": [
    "colormap = cm.get_cmap('inferno')\n",
    "colors = colormap(point_uncertainties)[:, :3]  # Get RGB values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scene(threshold):\n",
    "    # Apply dynamic threshold\n",
    "    threshold_mask = point_uncertainties >= threshold\n",
    "    filtered_xyz_thresholded = filtered_xyz[threshold_mask]\n",
    "    point_uncertainties_thresholded = point_uncertainties[threshold_mask]\n",
    "    colors_thresholded = colors[threshold_mask]\n",
    "\n",
    "    # Define sphere sizes for the remaining points\n",
    "    sphere_sizes_thresholded = 0.05 + point_uncertainties_thresholded * 0.001\n",
    "\n",
    "    # Create spheres for the thresholded points\n",
    "    spheres = []\n",
    "    for point, size, color in zip(filtered_xyz_thresholded, sphere_sizes_thresholded, colors_thresholded):\n",
    "        sphere = trimesh.primitives.Sphere(\n",
    "            radius=size, center=point, subdivisions=2  # Subdivisions for smoothness\n",
    "        )\n",
    "        sphere.visual.vertex_colors = (color * 255).astype(np.uint8)\n",
    "        spheres.append(sphere)\n",
    "\n",
    "    # Add mesh for spatial context\n",
    "    density_np = averaged_rgb.mean(axis=1).reshape(N, N, N)  # Use the full averaged RGB for mesh visualization\n",
    "    vertices, triangles = mcubes.marching_cubes(density_np, 3 * np.mean(density_np))\n",
    "    vertices_scaled = (vertices / N) * (2 * scale) - scale\n",
    "    mesh = trimesh.Trimesh(vertices_scaled, triangles)\n",
    "\n",
    "    # Draw view direction vectors\n",
    "    center = np.array([0, 0, 0])  # Assume object is centered at the origin\n",
    "    view_lines = []\n",
    "    for direction in view_directions.cpu().numpy():\n",
    "        arrow_start = center\n",
    "        arrow_end = center + 3 * direction  # Make vectors 3x longer\n",
    "        line = trimesh.load_path(np.array([arrow_start, arrow_end]))\n",
    "        \n",
    "        # Assign red color to the path\n",
    "        line_colors = np.array([[255, 0, 0, 255]] * len(line.entities))  # RGBA for red, fully opaque\n",
    "        line.colors = line_colors  # Assign per-entity colors\n",
    "        line.width = 2.0  # Set line thickness\n",
    "        view_lines.append(line)\n",
    "\n",
    "    # Combine the mesh, spheres, and view vectors into a single scene\n",
    "    scene = trimesh.Scene([mesh] + spheres + view_lines)\n",
    "\n",
    "    # Show the scene\n",
    "    scene.export(\"scene.glb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396fc128671b4f87b0919fb54e1721ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='threshold', max=1.0, step=0.01), Output()), _dom_cla…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_scene(threshold)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "interact(update_scene, threshold=FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf3Dchange",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
