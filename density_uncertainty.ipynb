{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import os\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_models(config_path):\n",
    "    \"\"\"\n",
    "    Load all .pth files from the specified experiment directory using configuration details from a .conf file.\n",
    "\n",
    "    :param config_path: Path to the configuration .conf file.\n",
    "    :return: A list of loaded models or data from the .pth files.\n",
    "    \"\"\"\n",
    "    # Create a ConfigParser object\n",
    "    config = configparser.ConfigParser()\n",
    "\n",
    "    # Read the configuration from the .conf file\n",
    "    config.read(config_path)\n",
    "\n",
    "    if not os.path.exists(config_path):\n",
    "        print(f\"Configuration file {config_path} does not exist.\")\n",
    "    elif os.path.getsize(config_path) == 0:\n",
    "        print(f\"Configuration file {config_path} is empty.\")\n",
    "    else:\n",
    "        print(f\"Configuration file {config_path} is found and has content.\")\n",
    "\n",
    "    # Print out all sections and keys for debugging\n",
    "    print(\"Sections found in config:\", config.sections())\n",
    "    for section in config.sections():\n",
    "        print(f\"Keys in section '{section}':\", config.options(section))\n",
    "\n",
    "    # Extract the base directory and experiment name from the config\n",
    "    try:\n",
    "        base_directory = config['EXPERIMENT']['base_directory']\n",
    "        experiment_name = config['EXPERIMENT']['experiment_name']\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing configuration key: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Construct the full path to the experiment directory\n",
    "    experiment_directory = os.path.join(os.path.join(base_directory, experiment_name), 'models')\n",
    "\n",
    "    # Initialize a list to store the loaded models or data\n",
    "    loaded_models = []\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.isdir(experiment_directory):\n",
    "        print(f\"Directory {experiment_directory} does not exist.\")\n",
    "        return loaded_models\n",
    "\n",
    "    # Iterate over all files in the experiment directory\n",
    "    for filename in os.listdir(experiment_directory):\n",
    "        # Check if the file has a .pth extension\n",
    "        if filename.endswith('.pth'):\n",
    "            # Construct the full path to the .pth file\n",
    "            file_path = os.path.join(experiment_directory, filename)\n",
    "\n",
    "            # Load the .pth file\n",
    "            try:\n",
    "                loaded_model = torch.load(file_path).to(device)\n",
    "\n",
    "                # Append the loaded model or data to the list\n",
    "                loaded_models.append(loaded_model)\n",
    "                print(f\"Loaded {filename} successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {filename}: {e}\")\n",
    "\n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "config_path = 'configs/experiment1.conf'  # Path to the config file\n",
    "\n",
    "# Load the models for the specified experiment\n",
    "models = load_experiment_models(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the densities\n",
    "N = 100\n",
    "scale = 1.5\n",
    "\n",
    "x = torch.linspace(-scale, scale, N)\n",
    "y = torch.linspace(-scale, scale, N)\n",
    "z = torch.linspace(-scale, scale, N)\n",
    "\n",
    "x, y, z = torch.meshgrid((x, y, z))\n",
    "\n",
    "xyz = torch.cat((x.reshape(-1, 1),\n",
    "                 y.reshape(-1, 1),\n",
    "                 z.reshape(-1, 1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arithmetic mean of each point (x,y,z) in our 3D grid\n",
    "densities = []\n",
    "for model in models:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, density = model.forward(xyz.to(device), torch.zeros_like(xyz).to(device))\n",
    "    \n",
    "    #density = density.cpu().numpy().reshape(N, N, N)\n",
    "    density = density.view(N, N, N)\n",
    "    densities.append(density)\n",
    "\n",
    "densities_tensor = torch.stack(densities)\n",
    "mean_density = torch.mean(densities_tensor, dim=0) # calculates the arithmetic mean for every point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densities[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all densities across the 7 models, substract the model density from the mean\n",
    "squared_diffs = []\n",
    "\n",
    "for model_density in densities: # for each model, subtact the mean density from each element.\n",
    "\n",
    "    squared_diffs.append(torch.square(torch.sub(model_density, mean_density))) # squared diffference for all points\n",
    "\n",
    "tensor_sum = torch.sum(torch.stack(squared_diffs), dim=0)\n",
    "divisor = len(models) - 1\n",
    "sample_variance = torch.div(tensor_sum, divisor)\n",
    "coeff_variation = torch.div(torch.sqrt(sample_variance), mean_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_variation = coeff_variation.cpu().numpy().reshape(N, N, N)\n",
    "sample_variance = sample_variance.cpu().numpy().reshape(N, N, N)\n",
    "mean_density = mean_density.cpu().numpy().reshape(N, N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the average value of the tensor\n",
    "# average_value = torch.mean(sample_variance)\n",
    "\n",
    "# print(\"Average value of the tensor:\", average_value.item())\n",
    "\n",
    "# torch.max(sample_variance), torch.min(sample_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "type(sample_variance), np.shape(sample_variance), np.max(sample_variance), np.min(sample_variance), np.mean(sample_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# arr1 = np.array([.1,1.5,3,1,2.3])\n",
    "# arr2 = np.array([50,60,55,52,57])\n",
    "# arr1_u = arr1 / 122.864\n",
    "# arr2_u = arr2 / 122.864\n",
    "\n",
    "# # find mean of each\n",
    "# mean1 = arr1_u.mean()\n",
    "# mean2 = arr2_u.mean()\n",
    "\n",
    "# # find sample variances\n",
    "# s21 = 0\n",
    "# s22 = 0\n",
    "# for i in range(len(arr1)):\n",
    "#     s21 += (arr1_u[i]-mean1)**2\n",
    "#     s22 += (arr2_u[i]-mean2)**2\n",
    "\n",
    "# s21 = s21 / (len(arr1) - 1)\n",
    "# s22 = s22 / (len(arr2) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "#pv.set_jupyter_backend('client')\n",
    "\n",
    "# Example: Assuming sample_variance is a 100x100x100 ndarray and threshold is the threshold scalar value\n",
    "\n",
    "# Set a threshold scalar value\n",
    "threshold = 100  # Example threshold value\n",
    "\n",
    "# Find the coordinates of points above the threshold\n",
    "above_threshold_mask = mean_density > threshold\n",
    "x_coords, y_coords, z_coords = np.where(above_threshold_mask)\n",
    "\n",
    "# Extract the values of points above the threshold\n",
    "values = mean_density[above_threshold_mask]\n",
    "\n",
    "# Create a PyVista Plotter\n",
    "plotter = pv.Plotter(title=\"Coefficent of variation\")\n",
    "\n",
    "# Add the points to the plotter\n",
    "plotter.add_points(np.column_stack((x_coords, y_coords, z_coords)), scalars=values, cmap=\"inferno\")\n",
    "\n",
    "# Show the plotter window\n",
    "plotter.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(coeff_variation), np.shape(coeff_variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_mask = np.load('monkey_mask.npy') # [3,len(points)]\n",
    "\n",
    "x_coords, y_coords, z_coords = object_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no threshold\n",
    "values = mean_density[x_coords.reshape(-1),y_coords.reshape(-1),z_coords.reshape(-1)]\n",
    "\n",
    "# With threshold\n",
    "threshold = 100  # Example threshold value\n",
    "above_threshold_mask = values > threshold\n",
    "# x_coords, y_coords, z_coords = np.where(above_threshold_mask)\n",
    "above_threshold_values = values[above_threshold_mask]\n",
    "above_threshold_coords = np.vstack((x_coords[above_threshold_mask], \n",
    "                                    y_coords[above_threshold_mask], \n",
    "                                    z_coords[above_threshold_mask])).T\n",
    "\n",
    "\n",
    "# Create a PyVista Plotter\n",
    "plotter = pv.Plotter(title=\"Coefficent of variation\")\n",
    "\n",
    "# Add the points to the plotter\n",
    "#plotter.add_points(np.column_stack((x_coords, y_coords, z_coords)), scalars=above_threshold_coords, cmap=\"inferno\")\n",
    "plotter.add_points(above_threshold_coords, scalars=above_threshold_values, cmap=\"inferno\")\n",
    "# Show the plotter window\n",
    "plotter.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf3Dchange",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
